{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ezBIDS CLI Demo: UK Biobank Example DICOMs\n",
    "\n",
    "This notebook demonstrates converting DICOM data to BIDS format using `ezbids-cli`.\n",
    "\n",
    "We'll showcase:\n",
    "- **Multi-modality conversion**: T1w, FLAIR, resting-state fMRI, and DWI\n",
    "- **Automatic detection**: How ezbids identifies datatypes, suffixes, and entities\n",
    "- **Two-stage workflow**: Analyze data, review, then apply conversion\n",
    "- **Configuration files**: Reusable settings for consistent conversions\n",
    "- **Validation**: BIDS compliance checking\n",
    "\n",
    "Data source: [UK Biobank Example DICOMs](https://biobank.ndph.ox.ac.uk/ukb/label.cgi?id=507)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Install dependencies and configure working directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ezbids-cli (uncomment one option)\n",
    "# !pip install ezbids-cli  # From PyPI\n",
    "!pip install -e .. --quiet  # From local source (development)\n",
    "\n",
    "# Install ipyniivue for visualization\n",
    "!pip install ipyniivue --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from ipyniivue import NiiVue\n",
    "\n",
    "# Working directories\n",
    "WORK_DIR = Path(\"demo_data\")\n",
    "DICOM_DIR = WORK_DIR / \"dicoms\"\n",
    "BIDS_DIR = WORK_DIR / \"bids_output\"\n",
    "ANALYSIS_DIR = WORK_DIR / \"analysis\"\n",
    "\n",
    "for d in [WORK_DIR, DICOM_DIR, ANALYSIS_DIR]:\n",
    "    d.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Working directory: {WORK_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download UK Biobank Example DICOMs\n",
    "\n",
    "UK Biobank provides publicly accessible example DICOM datasets. We'll download four modalities to demonstrate multi-modal conversion:\n",
    "\n",
    "| Modality | BIDS Type | Description |\n",
    "|----------|-----------|-------------|\n",
    "| T1 | anat/T1w | Structural MPRAGE |\n",
    "| T2 FLAIR | anat/FLAIR | Fluid-attenuated inversion recovery |\n",
    "| Resting fMRI | func/bold | Resting-state functional MRI |\n",
    "| DWI | dwi/dwi | Diffusion-weighted imaging |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK Biobank example DICOM URLs\n",
    "UKB_EXAMPLES = {\n",
    "    \"t1\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_t1.zip\",\n",
    "    \"t2flair\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_t2flair.zip\",\n",
    "    \"rest_fmri\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_rest.zip\",\n",
    "    \"dwi\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_mbdif.zip\",\n",
    "    \"swi\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_suswt.zip\",\n",
    "}\n",
    "\n",
    "def download_and_extract(name: str, url: str, target_dir: Path) -> Path:\n",
    "    \"\"\"Download and extract a zip file.\"\"\"\n",
    "    zip_path = target_dir / f\"{name}.zip\"\n",
    "    extract_dir = target_dir / name\n",
    "    \n",
    "    if extract_dir.exists():\n",
    "        print(f\"  {name}: already exists, skipping\")\n",
    "        return extract_dir\n",
    "    \n",
    "    print(f\"  {name}: downloading...\", end=\" \", flush=True)\n",
    "    urlretrieve(url, zip_path)\n",
    "    \n",
    "    print(\"extracting...\", end=\" \", flush=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        zf.extractall(extract_dir)\n",
    "    zip_path.unlink()\n",
    "    \n",
    "    file_count = sum(1 for f in extract_dir.rglob(\"*\") if f.is_file())\n",
    "    print(f\"done ({file_count} files)\")\n",
    "    return extract_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all four modalities\n",
    "# Note: rest_fmri is ~500MB, others are smaller\n",
    "datasets_to_download = [\"t1\", \"t2flair\", \"rest_fmri\", \"dwi\"]\n",
    "\n",
    "print(\"Downloading UK Biobank example DICOMs...\\n\")\n",
    "for name in datasets_to_download:\n",
    "    download_and_extract(name, UKB_EXAMPLES[name], DICOM_DIR)\n",
    "\n",
    "print(\"\\nDownload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what we downloaded\n",
    "print(\"Downloaded DICOM directories:\")\n",
    "print(\"=\" * 40)\n",
    "for d in sorted(DICOM_DIR.iterdir()):\n",
    "    if d.is_dir():\n",
    "        file_count = sum(1 for f in d.rglob(\"*\") if f.is_file())\n",
    "        print(f\"  {d.name}/ ({file_count} files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-Command Conversion\n",
    "\n",
    "The simplest way to use ezbids-cli: a single command that handles everything.\n",
    "\n",
    "```bash\n",
    "ezbids convert <input_dir> --output-dir <output_dir>\n",
    "```\n",
    "\n",
    "This will:\n",
    "1. Discover all DICOM files\n",
    "2. Convert to NIfTI using dcm2niix\n",
    "3. Identify datatypes and suffixes (T1w, FLAIR, bold, dwi, etc.)\n",
    "4. Extract BIDS entities (task, direction, run, etc.)\n",
    "5. Organize into BIDS directory structure\n",
    "6. Validate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean previous output if it exists\n",
    "if BIDS_DIR.exists():\n",
    "    shutil.rmtree(BIDS_DIR)\n",
    "\n",
    "# Run the conversion\n",
    "!ezbids convert {DICOM_DIR} --output-dir {BIDS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resulting BIDS structure\n",
    "def show_tree(path: Path, prefix: str = \"\", max_depth: int = 4, current_depth: int = 0):\n",
    "    \"\"\"Display directory tree.\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    items = sorted(path.iterdir())\n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        connector = \"\\u2514\\u2500\\u2500 \" if is_last else \"\\u251c\\u2500\\u2500 \"\n",
    "        print(f\"{prefix}{connector}{item.name}\")\n",
    "        \n",
    "        if item.is_dir():\n",
    "            extension = \"    \" if is_last else \"\\u2502   \"\n",
    "            show_tree(item, prefix + extension, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"BIDS Output Structure\")\n",
    "print(\"=\" * 50)\n",
    "if BIDS_DIR.exists():\n",
    "    show_tree(BIDS_DIR)\n",
    "else:\n",
    "    print(\"No output yet - run the conversion cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Converted Data\n",
    "\n",
    "Let's view the converted NIfTI files using ipyniivue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all NIfTI files in the BIDS output\n",
    "nifti_files = sorted(BIDS_DIR.rglob(\"*.nii.gz\"))\n",
    "\n",
    "print(\"Converted NIfTI files:\")\n",
    "print(\"-\" * 60)\n",
    "for f in nifti_files:\n",
    "    # Show path relative to BIDS dir\n",
    "    rel_path = f.relative_to(BIDS_DIR)\n",
    "    print(f\"  {rel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the T1w anatomical scan\n",
    "t1_files = [f for f in nifti_files if \"T1w\" in f.name]\n",
    "if t1_files:\n",
    "    print(f\"Viewing: {t1_files[0].name}\")\n",
    "    nv = NiiVue()\n",
    "    nv.load_volumes([{\"path\": str(t1_files[0])}])\n",
    "    display(nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the FLAIR scan\n",
    "flair_files = [f for f in nifti_files if \"FLAIR\" in f.name]\n",
    "if flair_files:\n",
    "    print(f\"Viewing: {flair_files[0].name}\")\n",
    "    nv = NiiVue()\n",
    "    nv.load_volumes([{\"path\": str(flair_files[0])}])\n",
    "    display(nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DWI scan\n",
    "dwi_files = [f for f in nifti_files if \"dwi\" in f.name.lower() and f.name.endswith(\"_dwi.nii.gz\")]\n",
    "if dwi_files:\n",
    "    print(f\"Viewing: {dwi_files[0].name}\")\n",
    "    nv = NiiVue()\n",
    "    nv.load_volumes([{\"path\": str(dwi_files[0])}])\n",
    "    display(nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding What Was Detected\n",
    "\n",
    "Let's use the programmatic API to understand exactly what ezbids detected and how it made its decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ezbids_cli.core.analyzer import Analyzer\n",
    "\n",
    "# Run analysis (without conversion) to inspect what was detected\n",
    "analyzer = Analyzer(DICOM_DIR, ANALYSIS_DIR)\n",
    "analysis = analyzer.analyze()\n",
    "\n",
    "print(f\"Analysis Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Subjects found: {len(analysis.get('subjects', []))}\")\n",
    "print(f\"Acquisitions found: {len(analysis.get('objects', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed detection results for each acquisition\n",
    "print(\"Detected Acquisitions\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, obj in enumerate(analysis.get(\"objects\", []), 1):\n",
    "    datatype = obj.get(\"_datatype\", \"unknown\")\n",
    "    suffix = obj.get(\"_suffix\", \"unknown\")\n",
    "    bids_type = f\"{datatype}/{suffix}\"\n",
    "    entities = obj.get(\"_entities\", {})\n",
    "    series_desc = obj.get(\"SeriesDescription\", \"N/A\")\n",
    "    \n",
    "    print(f\"\\n[{i}] {bids_type}\")\n",
    "    print(f\"    Series: {series_desc}\")\n",
    "    \n",
    "    # Show extracted entities\n",
    "    entity_items = [(k, v) for k, v in entities.items() if k not in [\"subject\", \"session\"] and v]\n",
    "    if entity_items:\n",
    "        entity_str = \", \".join(f\"{k}={v}\" for k, v in entity_items)\n",
    "        print(f\"    Entities: {entity_str}\")\n",
    "    \n",
    "    # Show any messages or warnings\n",
    "    if obj.get(\"_message\"):\n",
    "        print(f\"    Note: {obj['_message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the JSON sidecar for one acquisition\n",
    "# This shows the metadata extracted from DICOM headers\n",
    "\n",
    "# Find a JSON sidecar file\n",
    "json_files = sorted(BIDS_DIR.rglob(\"*.json\"))\n",
    "# Filter to acquisition sidecars (not dataset_description.json, etc.)\n",
    "sidecar_files = [f for f in json_files if f.parent.name in [\"anat\", \"func\", \"dwi\", \"fmap\", \"perf\"]]\n",
    "\n",
    "if sidecar_files:\n",
    "    example_sidecar = sidecar_files[0]\n",
    "    print(f\"Example JSON sidecar: {example_sidecar.name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    with open(example_sidecar) as f:\n",
    "        sidecar_data = json.load(f)\n",
    "    \n",
    "    # Show key fields\n",
    "    key_fields = [\n",
    "        \"Modality\", \"MagneticFieldStrength\", \"Manufacturer\", \"ManufacturersModelName\",\n",
    "        \"RepetitionTime\", \"EchoTime\", \"FlipAngle\", \"SliceThickness\",\n",
    "        \"PhaseEncodingDirection\", \"EffectiveEchoSpacing\",\n",
    "    ]\n",
    "    \n",
    "    for field in key_fields:\n",
    "        if field in sidecar_data:\n",
    "            print(f\"  {field}: {sidecar_data[field]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Two-Stage Workflow\n",
    "\n",
    "For more control, you can separate analysis from conversion:\n",
    "\n",
    "1. **Analyze**: Detect and classify acquisitions, save to JSON\n",
    "2. **Review**: Inspect/modify the analysis (manually or via TUI)\n",
    "3. **Apply**: Convert using the reviewed analysis\n",
    "\n",
    "This is useful when you want to:\n",
    "- Review what will be converted before committing\n",
    "- Manually correct misidentified acquisitions\n",
    "- Exclude certain scans from conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Analyze and save results\n",
    "!ezbids analyze {DICOM_DIR} --output-dir {ANALYSIS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the analysis output files\n",
    "print(\"Analysis output files:\")\n",
    "print(\"-\" * 40)\n",
    "for f in sorted(ANALYSIS_DIR.iterdir()):\n",
    "    if f.is_file():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the analysis JSON\n",
    "analysis_file = ANALYSIS_DIR / \"ezBIDS_core.json\"\n",
    "\n",
    "if analysis_file.exists():\n",
    "    with open(analysis_file) as f:\n",
    "        saved_analysis = json.load(f)\n",
    "    \n",
    "    print(\"Analysis file structure:\")\n",
    "    print(\"-\" * 40)\n",
    "    for key in saved_analysis.keys():\n",
    "        value = saved_analysis[key]\n",
    "        if isinstance(value, list):\n",
    "            print(f\"  {key}: [{len(value)} items]\")\n",
    "        elif isinstance(value, dict):\n",
    "            print(f\"  {key}: {{...}}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could modify the analysis here programmatically\n",
    "# For example, to exclude an acquisition or change its type:\n",
    "#\n",
    "# saved_analysis[\"objects\"][0][\"_exclude\"] = True\n",
    "# saved_analysis[\"objects\"][1][\"_datatype\"] = \"anat\"\n",
    "# saved_analysis[\"objects\"][1][\"_suffix\"] = \"T2w\"\n",
    "#\n",
    "# with open(analysis_file, \"w\") as f:\n",
    "#     json.dump(saved_analysis, f, indent=2)\n",
    "\n",
    "print(\"Analysis ready for review.\")\n",
    "print(\"\\nTo use the interactive TUI reviewer, run:\")\n",
    "print(f\"  ezbids review {analysis_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Apply the analysis to create BIDS output\n",
    "BIDS_DIR_STAGED = WORK_DIR / \"bids_staged\"\n",
    "if BIDS_DIR_STAGED.exists():\n",
    "    shutil.rmtree(BIDS_DIR_STAGED)\n",
    "\n",
    "!ezbids apply {analysis_file} {BIDS_DIR_STAGED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the staged output matches\n",
    "print(\"Staged BIDS Output\")\n",
    "print(\"=\" * 50)\n",
    "if BIDS_DIR_STAGED.exists():\n",
    "    show_tree(BIDS_DIR_STAGED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration-Based Conversion\n",
    "\n",
    "For reproducible conversions across multiple datasets, you can use a YAML configuration file.\n",
    "\n",
    "This is useful for:\n",
    "- Applying the same settings to multiple subjects/sessions\n",
    "- Sharing conversion settings with collaborators\n",
    "- Documenting exactly how data was converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a config file from existing analysis\n",
    "!ezbids init-config {DICOM_DIR} --output {WORK_DIR}/my_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the generated config\n",
    "config_file = WORK_DIR / \"my_config.yaml\"\n",
    "if config_file.exists():\n",
    "    print(\"Generated configuration:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(config_file.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a custom config\n",
    "custom_config = \"\"\"\n",
    "version: \"1.0\"\n",
    "\n",
    "dataset:\n",
    "  name: \"UK Biobank Demo\"\n",
    "  bids_version: \"1.9.0\"\n",
    "  authors:\n",
    "    - \"ezBIDS CLI Demo\"\n",
    "\n",
    "# Series matching rules (applied in order)\n",
    "series:\n",
    "  # T1-weighted structural\n",
    "  - match:\n",
    "      series_description: \".*T1.*MPRAGE.*\"\n",
    "    datatype: anat\n",
    "    suffix: T1w\n",
    "  \n",
    "  # FLAIR\n",
    "  - match:\n",
    "      series_description: \".*FLAIR.*\"\n",
    "    datatype: anat\n",
    "    suffix: FLAIR\n",
    "  \n",
    "  # Resting-state fMRI\n",
    "  - match:\n",
    "      series_description: \".*rest.*fMRI.*\"\n",
    "    datatype: func\n",
    "    suffix: bold\n",
    "    entities:\n",
    "      task: rest\n",
    "  \n",
    "  # DWI\n",
    "  - match:\n",
    "      series_description: \".*dMRI.*\"\n",
    "    datatype: dwi\n",
    "    suffix: dwi\n",
    "\n",
    "output:\n",
    "  link_mode: hardlink  # hardlink, symlink, or copy\n",
    "  validate: true\n",
    "\"\"\"\n",
    "\n",
    "custom_config_path = WORK_DIR / \"custom_config.yaml\"\n",
    "custom_config_path.write_text(custom_config)\n",
    "print(\"Custom config written to:\", custom_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert using the custom config\n",
    "BIDS_DIR_CONFIG = WORK_DIR / \"bids_from_config\"\n",
    "if BIDS_DIR_CONFIG.exists():\n",
    "    shutil.rmtree(BIDS_DIR_CONFIG)\n",
    "\n",
    "!ezbids convert {DICOM_DIR} --config {custom_config_path} --output-dir {BIDS_DIR_CONFIG}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation\n",
    "\n",
    "ezBIDS CLI includes the official `bids-validator` Python package for checking BIDS compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ezbids_cli.validation.validator import validate_dataset, print_validation_result\n",
    "\n",
    "print(\"Validating BIDS Dataset\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Path: {BIDS_DIR}\\n\")\n",
    "\n",
    "result = validate_dataset(BIDS_DIR)\n",
    "print_validation_result(result, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also validate from the command line:\n",
    "# !ezbids validate {BIDS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inspect Dataset Metadata\n",
    "\n",
    "Let's look at the dataset-level files that were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_description.json\n",
    "desc_file = BIDS_DIR / \"dataset_description.json\"\n",
    "if desc_file.exists():\n",
    "    print(\"dataset_description.json\")\n",
    "    print(\"=\" * 40)\n",
    "    with open(desc_file) as f:\n",
    "        print(json.dumps(json.load(f), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants.tsv\n",
    "participants_file = BIDS_DIR / \"participants.tsv\"\n",
    "if participants_file.exists():\n",
    "    print(\"participants.tsv\")\n",
    "    print(\"=\" * 40)\n",
    "    print(participants_file.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup\n",
    "\n",
    "Remove downloaded data and outputs when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up all demo data\n",
    "# shutil.rmtree(WORK_DIR)\n",
    "# print(\"Cleaned up demo data\")\n",
    "\n",
    "# Show disk usage\n",
    "import subprocess\n",
    "result = subprocess.run([\"du\", \"-sh\", str(WORK_DIR)], capture_output=True, text=True)\n",
    "print(f\"Demo data size: {result.stdout.strip()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
