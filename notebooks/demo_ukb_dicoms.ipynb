{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ezBIDS CLI Demo: UK Biobank Example DICOMs\n",
    "\n",
    "This notebook demonstrates converting DICOM data to BIDS format using `ezbids-cli`.\n",
    "\n",
    "We use publicly available example DICOM datasets from UK Biobank:\n",
    "- T1-weighted structural (MPRAGE)\n",
    "- T2 FLAIR structural\n",
    "- Resting-state fMRI\n",
    "- Diffusion MRI (DWI)\n",
    "- Susceptibility-weighted imaging (SWI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ezbids-cli if not already installed\n",
    "# !pip install ezbids-cli\n",
    "\n",
    "# For development, install from local source\n",
    "!pip install -e .. --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Create working directories\n",
    "WORK_DIR = Path(\"demo_data\")\n",
    "DICOM_DIR = WORK_DIR / \"dicoms\"\n",
    "BIDS_DIR = WORK_DIR / \"bids_output\"\n",
    "\n",
    "WORK_DIR.mkdir(exist_ok=True)\n",
    "DICOM_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download UK Biobank Example DICOMs\n",
    "\n",
    "UK Biobank provides publicly accessible example DICOM datasets for various MRI sequences.\n",
    "\n",
    "See: https://biobank.ndph.ox.ac.uk/ukb/label.cgi?id=507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK Biobank example DICOM URLs\n",
    "UKB_EXAMPLES = {\n",
    "    \"t1\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_t1.zip\",\n",
    "    \"t2flair\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_t2flair.zip\",\n",
    "    \"rest_fmri\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_rest.zip\",\n",
    "    \"dwi\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_mbdif.zip\",\n",
    "    \"swi\": \"https://biobank.ndph.ox.ac.uk/ukb/ukb/examples/eg_brain_suswt.zip\",\n",
    "}\n",
    "\n",
    "def download_and_extract(name: str, url: str, target_dir: Path) -> Path:\n",
    "    \"\"\"Download and extract a zip file.\"\"\"\n",
    "    zip_path = target_dir / f\"{name}.zip\"\n",
    "    extract_dir = target_dir / name\n",
    "    \n",
    "    if extract_dir.exists():\n",
    "        print(f\"  {name}: already exists, skipping download\")\n",
    "        return extract_dir\n",
    "    \n",
    "    print(f\"  {name}: downloading...\")\n",
    "    urlretrieve(url, zip_path)\n",
    "    \n",
    "    print(f\"  {name}: extracting...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        zf.extractall(extract_dir)\n",
    "    \n",
    "    # Clean up zip file\n",
    "    zip_path.unlink()\n",
    "    \n",
    "    return extract_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download selected example datasets\n",
    "# For a quick demo, we'll just use T1 and T2 FLAIR\n",
    "# Uncomment others as needed (note: fMRI is large ~500MB)\n",
    "\n",
    "print(\"Downloading UK Biobank example DICOMs...\")\n",
    "\n",
    "datasets_to_download = [\"t1\", \"t2flair\"]  # Quick demo\n",
    "# datasets_to_download = [\"t1\", \"t2flair\", \"dwi\"]  # Include DWI\n",
    "# datasets_to_download = list(UKB_EXAMPLES.keys())  # All datasets\n",
    "\n",
    "for name in datasets_to_download:\n",
    "    download_and_extract(name, UKB_EXAMPLES[name], DICOM_DIR)\n",
    "\n",
    "print(\"\\nDownload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what was downloaded\n",
    "print(\"Downloaded DICOM directories:\")\n",
    "for d in sorted(DICOM_DIR.iterdir()):\n",
    "    if d.is_dir():\n",
    "        dcm_count = len(list(d.rglob(\"*.dcm\"))) + len(list(d.rglob(\"*\") - set(d.rglob(\"*.dcm\"))))\n",
    "        print(f\"  {d.name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Schema\n",
    "\n",
    "ezBIDS CLI uses `bidsschematools` as the source of truth for BIDS compliance.\n",
    "Let's explore what the schema provides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ezbids_cli.schema import (\n",
    "    get_bids_version,\n",
    "    get_entity_order,\n",
    "    get_required_entities,\n",
    "    validate_suffix_for_datatype,\n",
    ")\n",
    "\n",
    "print(f\"BIDS Version: {get_bids_version()}\")\n",
    "print(f\"\\nEntity order (first 10): {get_entity_order()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required entities for different datatypes\n",
    "examples = [\n",
    "    (\"anat\", \"T1w\"),\n",
    "    (\"anat\", \"FLAIR\"),\n",
    "    (\"anat\", \"MEGRE\"),\n",
    "    (\"func\", \"bold\"),\n",
    "    (\"dwi\", \"dwi\"),\n",
    "    (\"fmap\", \"epi\"),\n",
    "]\n",
    "\n",
    "print(\"Required entities by datatype/suffix:\")\n",
    "print(\"-\" * 40)\n",
    "for datatype, suffix in examples:\n",
    "    required = get_required_entities(datatype, suffix)\n",
    "    print(f\"{datatype}/{suffix}: {required or '(none)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate some datatype/suffix combinations\n",
    "print(\"Validating datatype/suffix combinations:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "test_cases = [\n",
    "    (\"anat\", \"T1w\"),      # Valid\n",
    "    (\"anat\", \"bold\"),     # Invalid - bold is func\n",
    "    (\"func\", \"bold\"),     # Valid\n",
    "    (\"func\", \"T1w\"),      # Invalid - T1w is anat\n",
    "    (\"dwi\", \"dwi\"),       # Valid\n",
    "    (\"anat\", \"FLAIR\"),    # Valid\n",
    "]\n",
    "\n",
    "for datatype, suffix in test_cases:\n",
    "    is_valid, error = validate_suffix_for_datatype(datatype, suffix)\n",
    "    status = \"✓\" if is_valid else \"✗\"\n",
    "    msg = \"\" if is_valid else f\" ({error})\"\n",
    "    print(f\"{status} {datatype}/{suffix}{msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert DICOMs to BIDS\n",
    "\n",
    "Now let's convert the UK Biobank example DICOMs to BIDS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CLI to convert\n",
    "!ezbids convert {DICOM_DIR} --output-dir {BIDS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the resulting BIDS structure\n",
    "def show_tree(path: Path, prefix: str = \"\", max_depth: int = 3, current_depth: int = 0):\n",
    "    \"\"\"Display directory tree.\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    items = sorted(path.iterdir())\n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        connector = \"└── \" if is_last else \"├── \"\n",
    "        print(f\"{prefix}{connector}{item.name}\")\n",
    "        \n",
    "        if item.is_dir():\n",
    "            extension = \"    \" if is_last else \"│   \"\n",
    "            show_tree(item, prefix + extension, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"BIDS output structure:\")\n",
    "print(\"=\" * 40)\n",
    "if BIDS_DIR.exists():\n",
    "    for dataset_dir in BIDS_DIR.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            print(f\"\\n{dataset_dir.name}/\")\n",
    "            show_tree(dataset_dir)\n",
    "else:\n",
    "    print(\"No BIDS output yet - run the conversion cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmatic API\n",
    "\n",
    "You can also use ezBIDS CLI programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ezbids_cli.core.analyzer import Analyzer\n",
    "from ezbids_cli.convert.converter import BIDSConverter\n",
    "\n",
    "# Analyze the data\n",
    "analyzer = Analyzer(DICOM_DIR, work_dir=WORK_DIR / \"work\")\n",
    "analysis = analyzer.analyze()\n",
    "\n",
    "print(f\"Found {len(analysis.get('objects', []))} objects\")\n",
    "print(f\"Found {len(analysis.get('subjects', []))} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detected acquisitions\n",
    "print(\"Detected acquisitions:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for obj in analysis.get(\"objects\", []):\n",
    "    obj_type = obj.get(\"_type\", \"unknown\")\n",
    "    entities = obj.get(\"_entities\", {})\n",
    "    message = obj.get(\"_message\", \"\")\n",
    "    \n",
    "    # Build entity string\n",
    "    entity_str = \", \".join(f\"{k}={v}\" for k, v in entities.items() if k not in [\"subject\", \"session\"])\n",
    "    \n",
    "    print(f\"  {obj_type}\")\n",
    "    if entity_str:\n",
    "        print(f\"    entities: {entity_str}\")\n",
    "    if message:\n",
    "        print(f\"    message: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the BIDS Dataset\n",
    "\n",
    "If you have the BIDS validator installed, you can validate the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bids-validator is available\n",
    "import shutil\n",
    "\n",
    "if shutil.which(\"bids-validator\"):\n",
    "    print(\"Running BIDS validator...\")\n",
    "    !bids-validator {BIDS_DIR}/* --verbose\n",
    "else:\n",
    "    print(\"bids-validator not found. Install with: npm install -g bids-validator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove downloaded data when done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up\n",
    "# shutil.rmtree(WORK_DIR)\n",
    "# print(\"Cleaned up demo data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
